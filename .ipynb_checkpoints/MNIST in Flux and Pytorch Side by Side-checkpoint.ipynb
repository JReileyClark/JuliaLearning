{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will implement a simple convolutional neural net using Flux.jl to predict digits on the famous MNIST data set.  This is a canonical neural net example, so it's not particularly novel, but it's a welcome presence in any Data Scientists github.\n",
    "\n",
    "Additionally, we will pair the Julia code examples with a Python Example using Pytorch.  Most notable in this comparison are the similarities.  In almost all languages, the design and execution of neural nets is very similar both because they borrow from eachother things like naming conventions because it helps adoption, and also because Neural Nets have a common structure that can be exploited through generalizable code architecture. We will explore the latter similarities and differences here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Starting off, we will import the necessary packages.  If you don't already have the packages listed in your Julia or Python environments, uncomment the commented code before running.\n",
    "\n",
    "For this example, we are using the Julia Flux.jl package, which is the most popular package for working with Neural Networks in Julia.  This package is great because of its Zygote dependency which serves as the automatic differentiation engine of the package.  It also has many common neural network layer types, activation functions, and loss types.\n",
    "\n",
    "The Parameters.jl is imported because it contains helpful macros that allow us to create structs in a manner that improves readability, but also that is not possible in base Julia. I will point out the use of Parameters when the time comes and discuss more about its use.\n",
    "\n",
    "We import the Plots.jl package to handle any plotting we may need.  Plotting in Julia is strange at first because of it's simple sophistication.  Because julia's multiple dispatch, calling plot() on different types in julia can automatically generate plots that are relevant to that type.  I won't cover it much here, but it's very nice. One downside is that Plots.jl does not have all of the customizability of a package like Python's Matplotlib, though for almost all plots you'll like find Plots.jl an improvement.\n",
    "\n",
    "Next we import CUDA.jl. CUDA is a package that merged together multiple separate Cuda related packages into one (CuArrays,CUDAapi, etc).  CUDA contains all the necessary functionality to transform Julia arrays and structs into GPU compatible arrays. The beauty of multiple dispatch is that once we declare our arrays to be of a Cuda compatible type, then our code executes naturally on the GPU without additional functions or code.\n",
    "\n",
    "Finally, we import MLDatasets. MLDatasets contains some common benchmark datasets as well as a Dataloader which will help us split our data into smaller batches and lazily provide it to our NN as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ACTIVATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CUDA is on\n",
      "└ @ Main In[7]:16\n"
     ]
    }
   ],
   "source": [
    "# ################## JULIA CODE #########################\n",
    "\n",
    "\n",
    "# #using Pkg\n",
    "# #Pkg.add(\"Flux\")\n",
    "# #Pkg.add(\"MLDatasets\")\n",
    "# #Pkg.add(\"Parameters\")\n",
    "# #Pkg.add(\"CUDA\")\n",
    "\n",
    "\n",
    "# using Flux\n",
    "# using Parameters\n",
    "# using Plots\n",
    "# using MLDatasets\n",
    "# using CUDA: has_cuda\n",
    "\n",
    "\n",
    "# #This little bit of code is used in all of the Model Zoo examples as a way to test whether you have\n",
    "# # cuda gpu support. If so, CUDA is imported and we will process our model on the GPU.\n",
    "# if has_cuda()\n",
    "#     @info \"CUDA is on\"\n",
    "#     import CUDA\n",
    "#     CUDA.allowscalar(false)\n",
    "#     println(\"CUDA ACTIVATED\")\n",
    "# end\n",
    "\n",
    "\n",
    "# #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'vars' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below to download the torch and torchvision packages if you don't already have them.  Notice that there is only one package manager in Julia and that missing packages from Julia can be installed quite easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PYTHON CODE ########################\n",
    "\n",
    "\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} torch   # uncomment if Conda environment\n",
    "# !conda install --yes --prefix {sys.prefix} torchvision # uncomment if Conda environment\n",
    "\n",
    "# !{sys.executable} -m pip install torch # uncomment if not conda environment\n",
    "# !{sys.executable} -m pip install torchvision # uncomment if not conda environment\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import dataloader\n",
    "from torchvision import datasets\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you will notice right away is the time it take for the Julia packages to load. This is because Julia compiles the packages on import. This compile time is cause for a common \"time to first plot\" complaint in Julia. Plots.jl can take 30seconds+ to compile on some computers.  The benefits to that compilation, though, is very fast and interactive plots that put anything made by python and matplotlib to shame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = \"~\\\\GitHub\\JuliaLearning\\Data\" # replace with your directory of choice.\n",
    "train = datasets.MNIST(download_dir, download=True)\n",
    "test = datasets.MNIST(download_dir,train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "imgsize= (28,28,1)\n",
    "nclasses = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frustrating thing about learning deep learning models is that the architecture seems arbitrary.  Why Relu? Why a layer of that particular width? It turns out, that people just try things out and report their performance. Things that perform well get copied. Sometimes, people optimize over certain parameters using crossval and LOTS of compute. When things work, they get repeated. It's a mix of empirical results for particular datasets and heuristic approaches.\n",
    "\n",
    "Take for example the code from Flux.jl model zoon on convolutional NN for MNIST.. Why did they choose their layers the way the did? Why max pools at each layer? no explanation. Just works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# JULIA CODE #########################\n",
    "\n",
    "# # Lets create a struct to store our model arguments\n",
    "# # This will help organize our code and allow arguments to be passed into our functions in a clean and readable manner\n",
    "\n",
    "# # The @with_kw creates a constructor for our args type automatically\n",
    "# @with_kw mutable struct Args\n",
    "#     η::Float64 = 3e-3\n",
    "#     epochs::Int = 1\n",
    "#     batch_size = 50\n",
    "#     savepath::String = \"./\"\n",
    "#     device::Function = has_cuda() ? gpu : cpu #if cuda is available, use it!\n",
    "#     imgsize::Tuple = (28,28,1)\n",
    "#     nclasses::Int = 10\n",
    "# end\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cfcd3c51f9b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finally figured out why I was getting errors! You have to be careful with the dimensions of the dataset. In one of the modelzoo examples, they pull data using a DataLoader with MLDatasets.MNIST, with the other example they use Flux.Data.MNIST.  The dimensions of each are different. Also, they were flattening the data.\n",
    "\n",
    "After undoing the transformations and examinging the dimensions of the data, all that was required was converting a 28x28xN dataset into a 28x28x1xN.  The additional dimension made the dimensions match with the model params dimensions and everything began to work again.\n",
    "\n",
    "Dimensions matter, I wont forget it. I've been debugging this model for a full day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getdata (generic function with 1 method)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a function to get data\n",
    "args = Args\n",
    "function getdata(args)\n",
    "    # Loading Dataset\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "    # Reshape Data from 28x28xN to 28x28x1xN, not that this only works for the convolutional model\n",
    "    xtrain = reshape(xtrain,size(xtrain)[1:2]...,1,size(xtrain)[3])\n",
    "    xtest = reshape(xtest,size(xtest)[1:2]...,1,size(xtest)[3])\n",
    "\n",
    "    # One-hot-encode the labels\n",
    "    ytrain, ytest = Flux.onehotbatch(ytrain, 0:9), Flux.onehotbatch(ytest, 0:9)\n",
    "\n",
    "    # Batching\n",
    "    train_data = Flux.Data.DataLoader(xtrain, ytrain, batchsize=args.batch_size, shuffle=true)\n",
    "    test_data = Flux.Data.DataLoader(xtest, ytest, batchsize=args.batch_size)\n",
    "    return train_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_conv_model (generic function with 1 method)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function build_conv_model(args)\n",
    "    cnn_output_size = Int.(floor.([args.imgsize[1]/8,args.imgsize[2]/8,32]))\n",
    "    return Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one using `Flux.flatten`, at this point it should be (3, 3, 32, N)\n",
    "    flatten,\n",
    "    Dense(prod(cnn_output_size), 10))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(row) = (3, 3, 1, 16)\n",
      "size(row) = (16,)\n",
      "size(row) = (3, 3, 16, 32)\n",
      "size(row) = (32,)\n",
      "size(row) = (3, 3, 32, 32)\n",
      "size(row) = (32,)\n",
      "size(row) = (10, 288)\n",
      "size(row) = (10,)\n"
     ]
    }
   ],
   "source": [
    "m = build_conv_model(args)\n",
    "for row in params(m)\n",
    "    @show size(row)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_all(dataloader, model)\n",
    "    l = 0f0\n",
    "    for (x,y) in dataloader\n",
    "\n",
    "        l += Flux.Losses.logitcrossentropy(model(x), y)\n",
    "    end\n",
    "    l/length(dataloader)\n",
    "end\n",
    "\n",
    "function accuracy(data_loader, model)\n",
    "    acc = 0\n",
    "    for (x,y) in data_loader\n",
    "        acc += sum(Flux.onecold(cpu(model(x))) .== Flux.onecold(cpu(y)))*1 / size(x,4)\n",
    "    end\n",
    "    acc/length(data_loader)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\Bleep\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 2.2776525f0\n",
      "loss_all(train_data, m) = 2.248435f0\n",
      "loss_all(train_data, m) = 2.2152865f0\n",
      "loss_all(train_data, m) = 2.1728847f0\n",
      "loss_all(train_data, m) = 2.1165485f0\n",
      "loss_all(train_data, m) = 2.0444007f0\n",
      "loss_all(train_data, m) = 1.9534538f0\n",
      "loss_all(train_data, m) = 1.839233f0\n",
      "loss_all(train_data, m) = 1.7029536f0\n",
      "loss_all(train_data, m) = 1.5498775f0\n",
      "loss_all(train_data, m) = 1.3873558f0\n",
      "loss_all(train_data, m) = 1.2115502f0\n",
      "loss_all(train_data, m) = 1.0439117f0\n",
      "loss_all(train_data, m) = 0.8958241f0\n",
      "loss_all(train_data, m) = 0.7873061f0\n",
      "loss_all(train_data, m) = 0.69131976f0\n",
      "loss_all(train_data, m) = 0.62354285f0\n",
      "loss_all(train_data, m) = 0.5629688f0\n",
      "loss_all(train_data, m) = 0.5218593f0\n",
      "loss_all(train_data, m) = 0.49033296f0\n",
      "loss_all(train_data, m) = 0.4573032f0\n",
      "loss_all(train_data, m) = 0.44973817f0\n",
      "loss_all(train_data, m) = 0.41917577f0\n",
      "loss_all(train_data, m) = 0.40969753f0\n",
      "loss_all(train_data, m) = 0.366155f0\n",
      "loss_all(train_data, m) = 0.3984281f0\n",
      "loss_all(train_data, m) = 0.38665375f0\n",
      "loss_all(train_data, m) = 0.33281797f0\n",
      "loss_all(train_data, m) = 0.37074852f0\n",
      "loss_all(train_data, m) = 0.3268847f0\n",
      "loss_all(train_data, m) = 0.30731598f0\n",
      "loss_all(train_data, m) = 0.32507506f0\n",
      "loss_all(train_data, m) = 0.31521198f0\n",
      "loss_all(train_data, m) = 0.27991918f0\n",
      "loss_all(train_data, m) = 0.27834147f0\n",
      "loss_all(train_data, m) = 0.2953042f0\n",
      "loss_all(train_data, m) = 0.26693738f0\n",
      "loss_all(train_data, m) = 0.25962853f0\n",
      "loss_all(train_data, m) = 0.26173237f0\n",
      "loss_all(train_data, m) = 0.23674507f0\n",
      "loss_all(train_data, m) = 0.236322f0\n",
      "loss_all(train_data, m) = 0.24373898f0\n",
      "loss_all(train_data, m) = 0.23854177f0\n",
      "loss_all(train_data, m) = 0.22493698f0\n",
      "loss_all(train_data, m) = 0.2130868f0\n",
      "loss_all(train_data, m) = 0.21520123f0\n",
      "loss_all(train_data, m) = 0.21511091f0\n",
      "loss_all(train_data, m) = 0.2034232f0\n",
      "loss_all(train_data, m) = 0.20103747f0\n",
      "loss_all(train_data, m) = 0.21713266f0\n",
      "loss_all(train_data, m) = 0.21267071f0\n",
      "loss_all(train_data, m) = 0.193492f0\n",
      "loss_all(train_data, m) = 0.17955445f0\n",
      "loss_all(train_data, m) = 0.18393146f0\n",
      "loss_all(train_data, m) = 0.20654628f0\n",
      "loss_all(train_data, m) = 0.20604107f0\n",
      "loss_all(train_data, m) = 0.17446212f0\n",
      "loss_all(train_data, m) = 0.16354387f0\n",
      "loss_all(train_data, m) = 0.17540231f0\n",
      "loss_all(train_data, m) = 0.17386374f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\Bleep\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.17277148f0\n",
      "loss_all(train_data, m) = 0.17605901f0\n",
      "loss_all(train_data, m) = 0.16929227f0\n",
      "loss_all(train_data, m) = 0.16183974f0\n",
      "loss_all(train_data, m) = 0.16953257f0\n",
      "loss_all(train_data, m) = 0.15832387f0\n",
      "loss_all(train_data, m) = 0.14549473f0\n",
      "loss_all(train_data, m) = 0.15611799f0\n",
      "loss_all(train_data, m) = 0.16809325f0\n",
      "loss_all(train_data, m) = 0.15138428f0\n",
      "loss_all(train_data, m) = 0.1408373f0\n",
      "loss_all(train_data, m) = 0.14237304f0\n",
      "loss_all(train_data, m) = 0.14286514f0\n",
      "loss_all(train_data, m) = 0.14565895f0\n",
      "loss_all(train_data, m) = 0.14595693f0\n",
      "loss_all(train_data, m) = 0.13978532f0\n",
      "loss_all(train_data, m) = 0.13584372f0\n",
      "loss_all(train_data, m) = 0.1364515f0\n",
      "loss_all(train_data, m) = 0.1331088f0\n",
      "loss_all(train_data, m) = 0.12994474f0\n",
      "loss_all(train_data, m) = 0.13306803f0\n",
      "loss_all(train_data, m) = 0.13463661f0\n",
      "loss_all(train_data, m) = 0.12684658f0\n",
      "loss_all(train_data, m) = 0.12401478f0\n",
      "loss_all(train_data, m) = 0.12391225f0\n",
      "loss_all(train_data, m) = 0.12158191f0\n",
      "loss_all(train_data, m) = 0.12080689f0\n",
      "loss_all(train_data, m) = 0.1246131f0\n",
      "loss_all(train_data, m) = 0.12591313f0\n",
      "loss_all(train_data, m) = 0.11862587f0\n",
      "loss_all(train_data, m) = 0.115729384f0\n",
      "loss_all(train_data, m) = 0.117760405f0\n",
      "loss_all(train_data, m) = 0.11642942f0\n",
      "loss_all(train_data, m) = 0.11318103f0\n",
      "loss_all(train_data, m) = 0.11304364f0\n",
      "loss_all(train_data, m) = 0.11159762f0\n",
      "loss_all(train_data, m) = 0.10870686f0\n",
      "loss_all(train_data, m) = 0.11007023f0\n",
      "loss_all(train_data, m) = 0.11127129f0\n",
      "loss_all(train_data, m) = 0.112297915f0\n",
      "loss_all(train_data, m) = 0.11125608f0\n",
      "loss_all(train_data, m) = 0.108256795f0\n",
      "loss_all(train_data, m) = 0.10575194f0\n",
      "loss_all(train_data, m) = 0.10648679f0\n",
      "loss_all(train_data, m) = 0.10774751f0\n",
      "loss_all(train_data, m) = 0.10834675f0\n",
      "loss_all(train_data, m) = 0.10875462f0\n",
      "loss_all(train_data, m) = 0.10883661f0\n",
      "loss_all(train_data, m) = 0.105238535f0\n",
      "loss_all(train_data, m) = 0.10241901f0\n",
      "loss_all(train_data, m) = 0.1073846f0\n",
      "loss_all(train_data, m) = 0.11054034f0\n",
      "loss_all(train_data, m) = 0.10740899f0\n",
      "loss_all(train_data, m) = 0.10047696f0\n",
      "loss_all(train_data, m) = 0.09623229f0\n",
      "loss_all(train_data, m) = 0.10265712f0\n",
      "loss_all(train_data, m) = 0.10783908f0\n",
      "loss_all(train_data, m) = 0.10593624f0\n",
      "loss_all(train_data, m) = 0.1034271f0\n",
      "loss_all(train_data, m) = 0.10077133f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\Bleep\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.099982806f0\n",
      "loss_all(train_data, m) = 0.108037524f0\n",
      "loss_all(train_data, m) = 0.113099895f0\n",
      "loss_all(train_data, m) = 0.10078212f0\n",
      "loss_all(train_data, m) = 0.101065464f0\n",
      "loss_all(train_data, m) = 0.10426667f0\n",
      "loss_all(train_data, m) = 0.09523626f0\n",
      "loss_all(train_data, m) = 0.09512427f0\n",
      "loss_all(train_data, m) = 0.10730527f0\n",
      "loss_all(train_data, m) = 0.09919824f0\n",
      "loss_all(train_data, m) = 0.08822267f0\n",
      "loss_all(train_data, m) = 0.09600993f0\n",
      "loss_all(train_data, m) = 0.09792208f0\n",
      "loss_all(train_data, m) = 0.09450543f0\n",
      "loss_all(train_data, m) = 0.094810806f0\n",
      "loss_all(train_data, m) = 0.09030684f0\n",
      "loss_all(train_data, m) = 0.08977219f0\n",
      "loss_all(train_data, m) = 0.09186118f0\n",
      "loss_all(train_data, m) = 0.095904894f0\n",
      "loss_all(train_data, m) = 0.090484954f0\n",
      "loss_all(train_data, m) = 0.086523674f0\n",
      "loss_all(train_data, m) = 0.09238333f0\n",
      "loss_all(train_data, m) = 0.091473594f0\n",
      "loss_all(train_data, m) = 0.088602796f0\n",
      "loss_all(train_data, m) = 0.087422095f0\n",
      "loss_all(train_data, m) = 0.08570615f0\n",
      "loss_all(train_data, m) = 0.083770804f0\n",
      "loss_all(train_data, m) = 0.08639f0\n",
      "loss_all(train_data, m) = 0.09048062f0\n",
      "loss_all(train_data, m) = 0.08589327f0\n",
      "loss_all(train_data, m) = 0.08194352f0\n",
      "loss_all(train_data, m) = 0.08156861f0\n",
      "loss_all(train_data, m) = 0.0828959f0\n",
      "loss_all(train_data, m) = 0.081052065f0\n",
      "loss_all(train_data, m) = 0.07973986f0\n",
      "loss_all(train_data, m) = 0.078846835f0\n",
      "loss_all(train_data, m) = 0.077623025f0\n",
      "loss_all(train_data, m) = 0.07691874f0\n",
      "loss_all(train_data, m) = 0.07857784f0\n",
      "loss_all(train_data, m) = 0.08118411f0\n",
      "loss_all(train_data, m) = 0.080362074f0\n",
      "loss_all(train_data, m) = 0.07728162f0\n",
      "loss_all(train_data, m) = 0.07473372f0\n",
      "loss_all(train_data, m) = 0.07648317f0\n",
      "loss_all(train_data, m) = 0.07828417f0\n",
      "loss_all(train_data, m) = 0.07941306f0\n",
      "loss_all(train_data, m) = 0.07957183f0\n",
      "loss_all(train_data, m) = 0.079232164f0\n",
      "loss_all(train_data, m) = 0.07772565f0\n",
      "loss_all(train_data, m) = 0.07604778f0\n",
      "loss_all(train_data, m) = 0.08065113f0\n",
      "loss_all(train_data, m) = 0.0848502f0\n",
      "loss_all(train_data, m) = 0.08388623f0\n",
      "loss_all(train_data, m) = 0.07871386f0\n",
      "loss_all(train_data, m) = 0.073401235f0\n",
      "loss_all(train_data, m) = 0.07673153f0\n",
      "loss_all(train_data, m) = 0.084069595f0\n",
      "loss_all(train_data, m) = 0.08500161f0\n",
      "loss_all(train_data, m) = 0.082005836f0\n",
      "loss_all(train_data, m) = 0.075696036f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\Bleep\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.07572326f0\n",
      "loss_all(train_data, m) = 0.080911025f0\n",
      "loss_all(train_data, m) = 0.08440767f0\n",
      "loss_all(train_data, m) = 0.0791189f0\n",
      "loss_all(train_data, m) = 0.0748353f0\n",
      "loss_all(train_data, m) = 0.077109165f0\n",
      "loss_all(train_data, m) = 0.07513511f0\n",
      "loss_all(train_data, m) = 0.07174246f0\n",
      "loss_all(train_data, m) = 0.07603264f0\n",
      "loss_all(train_data, m) = 0.07951641f0\n",
      "loss_all(train_data, m) = 0.07171177f0\n",
      "loss_all(train_data, m) = 0.0679686f0\n",
      "loss_all(train_data, m) = 0.070156656f0\n",
      "loss_all(train_data, m) = 0.074707836f0\n",
      "loss_all(train_data, m) = 0.076179735f0\n",
      "loss_all(train_data, m) = 0.071818344f0\n",
      "loss_all(train_data, m) = 0.07066049f0\n",
      "loss_all(train_data, m) = 0.07075668f0\n",
      "loss_all(train_data, m) = 0.07220874f0\n",
      "loss_all(train_data, m) = 0.074729f0\n",
      "loss_all(train_data, m) = 0.07058056f0\n",
      "loss_all(train_data, m) = 0.068514705f0\n",
      "loss_all(train_data, m) = 0.06803015f0\n",
      "loss_all(train_data, m) = 0.07101832f0\n",
      "loss_all(train_data, m) = 0.07264062f0\n",
      "loss_all(train_data, m) = 0.07038796f0\n",
      "loss_all(train_data, m) = 0.0680451f0\n",
      "loss_all(train_data, m) = 0.06809349f0\n",
      "loss_all(train_data, m) = 0.06949113f0\n",
      "loss_all(train_data, m) = 0.06956367f0\n",
      "loss_all(train_data, m) = 0.06978384f0\n",
      "loss_all(train_data, m) = 0.06930868f0\n",
      "loss_all(train_data, m) = 0.06554488f0\n",
      "loss_all(train_data, m) = 0.06383903f0\n",
      "loss_all(train_data, m) = 0.0655198f0\n",
      "loss_all(train_data, m) = 0.06594057f0\n",
      "loss_all(train_data, m) = 0.06571393f0\n",
      "loss_all(train_data, m) = 0.064721674f0\n",
      "loss_all(train_data, m) = 0.06269578f0\n",
      "loss_all(train_data, m) = 0.0634271f0\n",
      "loss_all(train_data, m) = 0.06593602f0\n",
      "loss_all(train_data, m) = 0.06544889f0\n",
      "loss_all(train_data, m) = 0.06064523f0\n",
      "loss_all(train_data, m) = 0.06003903f0\n",
      "loss_all(train_data, m) = 0.062086534f0\n",
      "loss_all(train_data, m) = 0.06461539f0\n",
      "loss_all(train_data, m) = 0.064676695f0\n",
      "loss_all(train_data, m) = 0.063006744f0\n",
      "loss_all(train_data, m) = 0.06084675f0\n",
      "loss_all(train_data, m) = 0.059626244f0\n",
      "loss_all(train_data, m) = 0.06463774f0\n",
      "loss_all(train_data, m) = 0.07044915f0\n",
      "loss_all(train_data, m) = 0.06986528f0\n",
      "loss_all(train_data, m) = 0.064308286f0\n",
      "loss_all(train_data, m) = 0.05881108f0\n",
      "loss_all(train_data, m) = 0.061900996f0\n",
      "loss_all(train_data, m) = 0.070587926f0\n",
      "loss_all(train_data, m) = 0.07357893f0\n",
      "loss_all(train_data, m) = 0.07092359f0\n",
      "loss_all(train_data, m) = 0.061587863f0\n",
      "loss_all(train_data, m) = 0.05909484f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\Bleep\\.julia\\packages\\Flux\\05b38\\src\\optimise\\train.jl:114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all(train_data, m) = 0.065258905f0\n",
      "loss_all(train_data, m) = 0.06945584f0\n",
      "loss_all(train_data, m) = 0.06427868f0\n",
      "loss_all(train_data, m) = 0.05975722f0\n",
      "loss_all(train_data, m) = 0.05984291f0\n",
      "loss_all(train_data, m) = 0.059782997f0\n",
      "loss_all(train_data, m) = 0.05778915f0\n",
      "loss_all(train_data, m) = 0.058370486f0\n",
      "loss_all(train_data, m) = 0.061772455f0\n",
      "loss_all(train_data, m) = 0.061132055f0\n",
      "loss_all(train_data, m) = 0.05827368f0\n",
      "loss_all(train_data, m) = 0.055853672f0\n",
      "loss_all(train_data, m) = 0.057137605f0\n",
      "loss_all(train_data, m) = 0.06007219f0\n",
      "loss_all(train_data, m) = 0.060703333f0\n",
      "loss_all(train_data, m) = 0.06133113f0\n",
      "loss_all(train_data, m) = 0.060369495f0\n",
      "loss_all(train_data, m) = 0.056733675f0\n",
      "loss_all(train_data, m) = 0.057668015f0\n",
      "loss_all(train_data, m) = 0.05788345f0\n",
      "loss_all(train_data, m) = 0.057998262f0\n",
      "loss_all(train_data, m) = 0.056284603f0\n",
      "loss_all(train_data, m) = 0.056328926f0\n",
      "loss_all(train_data, m) = 0.058143124f0\n",
      "loss_all(train_data, m) = 0.05863417f0\n",
      "loss_all(train_data, m) = 0.0572394f0\n",
      "loss_all(train_data, m) = 0.058914386f0\n",
      "loss_all(train_data, m) = 0.06008144f0\n",
      "loss_all(train_data, m) = 0.05739925f0\n",
      "loss_all(train_data, m) = 0.05784129f0\n",
      "loss_all(train_data, m) = 0.060509335f0\n",
      "loss_all(train_data, m) = 0.059633687f0\n",
      "loss_all(train_data, m) = 0.056240384f0\n",
      "loss_all(train_data, m) = 0.053962585f0\n",
      "loss_all(train_data, m) = 0.054096162f0\n",
      "loss_all(train_data, m) = 0.05499438f0\n",
      "loss_all(train_data, m) = 0.0571046f0\n",
      "loss_all(train_data, m) = 0.05738082f0\n",
      "loss_all(train_data, m) = 0.05475569f0\n",
      "loss_all(train_data, m) = 0.053710107f0\n",
      "loss_all(train_data, m) = 0.054845314f0\n",
      "loss_all(train_data, m) = 0.052222088f0\n",
      "loss_all(train_data, m) = 0.051603463f0\n",
      "loss_all(train_data, m) = 0.0525183f0\n",
      "loss_all(train_data, m) = 0.054679297f0\n",
      "loss_all(train_data, m) = 0.055936094f0\n",
      "loss_all(train_data, m) = 0.05458857f0\n",
      "loss_all(train_data, m) = 0.05168075f0\n",
      "loss_all(train_data, m) = 0.050759636f0\n",
      "loss_all(train_data, m) = 0.053872645f0\n",
      "loss_all(train_data, m) = 0.060000047f0\n",
      "loss_all(train_data, m) = 0.061066266f0\n",
      "loss_all(train_data, m) = 0.058022678f0\n",
      "loss_all(train_data, m) = 0.05136793f0\n",
      "loss_all(train_data, m) = 0.049214657f0\n",
      "loss_all(train_data, m) = 0.056130074f0\n",
      "loss_all(train_data, m) = 0.062492568f0\n",
      "loss_all(train_data, m) = 0.06375996f0\n",
      "loss_all(train_data, m) = 0.05441504f0\n",
      "accuracy(train_data, m) = 0.983083333333333\n",
      "accuracy(test_data, m) = 0.9832999999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9832999999999998"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Args(;epochs =5,batch_size=1000)\n",
    "function train(args)\n",
    "\n",
    "    # Construct model\n",
    "    m = build_conv_model(args)\n",
    "    train_data,test_data = getdata(args)\n",
    "    train_data = args.device.(train_data)\n",
    "    test_data = args.device.(test_data)\n",
    "    m = args.device(m)\n",
    "    loss(x,y) = Flux.Losses.logitcrossentropy(m(x), y)\n",
    "\n",
    "    ## Training\n",
    "    evalcb = () -> @show(loss_all(train_data, m))\n",
    "    opt = ADAM(args.η)\n",
    "\n",
    "    Flux.@epochs args.epochs Flux.train!(loss, params(m), train_data, opt, cb = evalcb)\n",
    "\n",
    "    @show accuracy(train_data, m)\n",
    "\n",
    "    @show accuracy(test_data, m)\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
